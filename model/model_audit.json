{"training_output": "[OK] Training started at 2025-10-17T22:18:08.127642\n[OK] Loaded 1022 human-labeled messages from database\nLabel distribution:\nlabel\nnoise               575\nhead_hunter         161\ninterview_invite    122\njob_alert            88\njob_application      60\nrejection            12\nreferral              2\nghosted               1\nfollow_up             1\nName: count, dtype: int64\n[Info] Filtered out 2 messages with blank/whitespace-only bodies.\n[Info] Merging rare classes ['referral', 'ghosted', 'follow_up'] into 'other'.\n[Info] Natural class distribution (before training):\nlabel\nnoise               573\nhead_hunter         161\ninterview_invite    122\njob_alert            88\njob_application      60\nrejection            12\nother                 4\nName: count, dtype: int64\n[OK] Training on 1020 human-labeled messages\nLabel distribution:\nlabel\nnoise               573\nhead_hunter         161\ninterview_invite    122\njob_alert            88\njob_application      60\nrejection            12\nother                 4\nName: count, dtype: int64\nTraining with 1020 samples across 7 classes\n                  precision    recall  f1-score   support\n\n     head_hunter       0.67      0.50      0.57        32\ninterview_invite       0.58      0.62      0.60        24\n       job_alert       0.79      0.83      0.81        18\n job_application       0.53      0.67      0.59        12\n           noise       0.91      0.74      0.82       115\n           other       0.00      0.00      0.00         1\n       rejection       0.09      0.50      0.15         2\n\n        accuracy                           0.69       204\n       macro avg       0.51      0.55      0.51       204\n    weighted avg       0.79      0.69      0.73       204\n\nMessage-level model artifacts saved to /model/\nModel trained on 1020 samples with 7 labels\n"}